{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df8ae2d-0c56-48f2-bef6-d7798800bfd5",
   "metadata": {},
   "source": [
    "# 01 - 對話資料生成 & 對話集格式介紹\n",
    "<div align=\"left\" style=\"line-height: 1;\">\n",
    "  <a href=\"https://discord.gg/Cx737yw4ed\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Twinkle%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "  <a href=\"https://huggingface.co/twinkle-ai\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Twinkle%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "      <a href=\"https://colab.research.google.com/github/ai-twinkle/llm-lab/blob/main/courses/2025-08-llm-dialogue-dataset/01_generate_dialogs.ipynb\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open 01_generate_dialogs In Colab\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "在這個 Lab，我們的目標是建立一份「可持續擴充」的對話資料集。主要的步驟如下：\n",
    "1. 重連 `Gemma-3-12B-it` API（使用 OpenAI SDK）\n",
    "2. 介紹對話資料的常見格式：**Alpaca**, **ShareGPT**，以及 **OpenAI** 格式（我們採用後者）\n",
    "3. 探討 `.jsonl` 格式與 `.parquet` 格式的優缺點，並說明 HF Hub 對 parquet 的轉換支援\n",
    "   (上傳 parquet 時 HF 會自動生成 `.parquet` 分支與 viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9f103-b0f0-468b-ba19-ca0b4556e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 重新初始化 API client\n",
    "API_KEY = \"\"  # 向 Twinkle AI 社群索取\n",
    "BASE_URL = \"https://litellm-ekkks8gsocw.dgx-coolify.apmic.ai\"\n",
    "MODEL = \"gemma-3-12b-it\"\n",
    "client = OpenAI(api_key=API_KEY, base_url=f\"{BASE_URL}/v1\")\n",
    "print(\"API client 已初始化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa29ba-2e60-4041-a21f-c8f328f61304",
   "metadata": {},
   "source": [
    "## 常見對話資料集格式比較\n",
    "\n",
    "- **Alpaca**：單輪指令 + 回答格式，通常是 Instruct tuning。（不適合多輪場景）\n",
    "- **ShareGPT**：使用以下格式，支援多角色多輪對話\n",
    "```json\n",
    "{\n",
    "    \"conversations\":[\n",
    "        {\"from\":\"human\",\"value\":\"...\"},\n",
    "        {\"from\":\"gpt\",\"value\":\"...\"}…]\n",
    "}\n",
    "```\n",
    "- **OpenAI Chat Messages**：最常用格式，像這樣：\n",
    "```json\n",
    "{\n",
    "  \"messages\":[\n",
    "      {\"role\":\"system\",\"content\":\"...\"},\n",
    "      {\"role\":\"user\",\"content\":\"...\"},\n",
    "      {\"role\":\"assistant\",\"content\":\"...\"}]\n",
    "}\n",
    "```\n",
    "Hugging Face 與多數工具都支援這種格式，且 OpenAI 本質上是 ShareGPT 格式的變體  ￼\n",
    "\n",
    "我們將採用 **OpenAI messages** 格式，並使用 `.jsonl` 儲存；另外，還有一種叫 `.parquet` 格式，他的優勢例如：\n",
    "- 高效壓縮、支援分欄讀取、大檔案操作快速\n",
    "- HF Hub 支援直接上傳 parquet，也會自動生成可公開瀏覽版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241fddab-ede4-4d95-86b7-569bee685087",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/01_wiki_data_format.png\" width=\"100%\"/><br/>\n",
    "  <em align=\"center\">圖 1：Wiki 對話格式示意圖</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd084c2b-1741-4a4d-8932-5e6dfdfafcfa",
   "metadata": {},
   "source": [
    "## JSONL vs Parquet 比較\n",
    "\n",
    "| 格式     | 優點                          | 缺點                         |\n",
    "|----------|-------------------------------|------------------------------|\n",
    "| `.jsonl` | 易讀、輕量、開發友善              | 檔案大、大量數據讀取效率較低   |\n",
    "| `.parquet` | 壓縮效果好、查詢效能高、支援 HF 轉換 | 不易直接閱讀，需使用工具處理   |\n",
    "\n",
    "注意：即使你上傳 `.jsonl`，HF Hub 也可能幫你生成 `.parquet` 分支，方便瀏覽與載入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a123e6-20c2-41d3-a235-7cfc8974c969",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/01_hf_parquet_branch.png\" width=\"100%\"/><br/>\n",
    "  <em>圖 2：HF Hub 自動生成的 .parquet 分支</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911efc9a-b8b9-4b28-92d8-c6d405ce31e3",
   "metadata": {},
   "source": [
    "## Reference-Free vs Reference-Based\n",
    "\n",
    "- **Reference-Free（無參考）**：用一些 seed prompt 引導模型生成。最早出自 [Self-Instruct: Aligning Language Models with Self-Generated Instructions\n",
    "](https://arxiv.org/abs/2212.10560)。\n",
    "- **Reference-Based（參考內容）**：使用真實資料片段（例如 Wiki 條目）作 prompt 佐料，讓生成內容更 grounded。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b3052-568d-4ab3-aa56-cc5fe2c942ab",
   "metadata": {},
   "source": [
    "### Reference-Free 實作\n",
    "\n",
    "在 Reference-Free 的情境下，我們並不依賴任何外部知識庫或文件，而是透過 **seed 任務 (seed task)** 來驅動模型自行生成資料。  \n",
    "這些 seed 任務通常包含一個 **instruction（指令）**，加上少量的 **instance（範例輸入/輸出對）**，作為模型模仿與延伸的起點。  \n",
    "\n",
    "這種方法的代表性工作是 *Self-Instruct*，它透過人工設計的一些高品質種子指令，讓模型去「舉一反三」產生更多指令和對應答案，最終建立出龐大的資料集。\n",
    "\n",
    "以下是一個取自 [self-instruct](https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl) seed 範例，主題是「早餐建議」。  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"seed_task_0\",\n",
    "  \"name\": \"breakfast_suggestion\",\n",
    "  \"instruction\": \"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\",\n",
    "  \"instances\": [\n",
    "    {\n",
    "      \"input\": \"\",\n",
    "      \"output\": \"Yes, you can have 1 oatmeal banana protein shake and 4 strips of bacon. The oatmeal banana protein shake may contain 1/2 cup oatmeal, 60 grams whey protein powder, 1/2 medium banana, 1 tbsp flaxseed oil and 1/2 cup water, totaling about 550 calories. The 4 strips of bacon contains about 200 calories.\"\n",
    "    }\n",
    "  ],\n",
    "  \"is_classification\": false\n",
    "}\n",
    "```\n",
    "說明：\n",
    "- id：任務的唯一識別碼。\n",
    "- name：任務名稱，方便辨識。\n",
    "- instruction：給模型的主要問題或指令。\n",
    "- instances：包含輸入/輸出對，本例中 input 為空，代表模型直接依 instruction 回答；output 是一個可能的解答。\n",
    "- is_classification：標記此任務是否為分類型問題（此例為否）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52128cae-647b-43da-913d-04aed64fc783",
   "metadata": {},
   "source": [
    "在實務中，我們會設計數十到數百個 seed 任務，涵蓋不同領域與指令型態，作為 Reference-Free 資料生成的核心基礎。\n",
    "\n",
    "不過，我們的作法並**不完全等同於 Self-Instruct**。\n",
    "相較於 Self-Instruct 的完整 pipeline（如：過濾、去重、迭代擴展），我們傾向採用更簡單直接的方式：\n",
    "\t1.\t人工撰寫少量高品質 seed 指令。\n",
    "\t2.\t要求模型基於這些 seed 產生新的 seed 指令（但僅限輸出 seed 本文，避免雜訊）。\n",
    "\t3.\t再利用這些新 seed 指令，由模型生成單輪問答配對。\n",
    "\n",
    "這樣的流程更輕量，雖然缺少複雜的篩選與多輪迭代，但對於課程實作與教學目標而言，已經能清楚展現 Reference-Free 的核心精神。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cbf67-aca6-4e63-854f-d08a889ea711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 以既有 seed 為出發點，要求 LLM 產生「不同但相關」的新 seed。\n",
    "# 重要：嚴格要求只輸出 seed 文字本身，不要任何多餘說明、標籤或引號。\n",
    "\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "# 假設你已經在前面初始化過 client / MODEL\n",
    "# client = OpenAI(api_key=API_KEY, base_url=f\"{BASE_URL}/v1\")\n",
    "# MODEL = \"gemma-3-12b-it\"\n",
    "\n",
    "base_seed = \"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\"\n",
    "\n",
    "seed_gen_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"你是一個資料生成器。你的任務是『根據給定 seed，產生一則不同但主題相關的 seed 指令』。\\n\"\n",
    "            \"務必遵守：\\n\"\n",
    "            \"1) 僅輸出新的 seed 指令本身（繁體中文）。\\n\"\n",
    "            \"2) 不要加任何解釋、前後文、引號、標點裝飾或標籤。\\n\"\n",
    "            \"3) 一至兩句話，清楚可執行。\\n\"\n",
    "            \"4) 避免重複與原 seed 完全相同的限制條件或措辭，但主題需相關。\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"這是原始 seed：\\n{base_seed}\\n\\n\"\n",
    "            \"請依規則產生一個新的 seed 指令（繁體中文）。只輸出新 seed 本文，其他一律不要。\"\n",
    "        )\n",
    "    },\n",
    "]\n",
    "\n",
    "resp_seed = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=seed_gen_messages,\n",
    "    temperature=0.9,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "new_seed_instruction_raw = resp_seed.choices[0].message.content.strip()\n",
    "\n",
    "# 基本清理：移除常見多餘字樣（保險）\n",
    "def sanitize_seed(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # 移除可能的程式碼圍欄或引號\n",
    "    text = re.sub(r\"^```.*?\\n|\\n```$\", \"\", text, flags=re.DOTALL)  # 去掉 ``` 區塊\n",
    "    text = text.strip(\"「」\\\"'` \\n\\t\")\n",
    "    # 去掉可能的前綴\n",
    "    text = re.sub(r\"^(新的?seed指令[:：]\\s*|seed[:：]\\s*|新指令[:：]\\s*)\", \"\", text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "new_seed_instruction = sanitize_seed(new_seed_instruction_raw)\n",
    "\n",
    "print(\"🔹 原始 seed：\", base_seed)\n",
    "print(\"🔸 新的 seed：\", new_seed_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef39f8-4d25-4404-bcc4-59c4da85a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 以「新的 seed 指令」當作 user 提問，生成單輪回答（assistant 一次回覆）。\n",
    "# 產出為 OpenAI messages 格式，可直接累積進 datasets.jsonl。\n",
    "\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "qa_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一位營養與飲食規劃的專家，請使用繁體中文，給出明確、可執行的建議。\"},\n",
    "    {\"role\": \"user\", \"content\": new_seed_instruction},\n",
    "]\n",
    "\n",
    "resp_qa = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=qa_messages,\n",
    "    temperature=0.7,\n",
    "    max_tokens=600,\n",
    ")\n",
    "\n",
    "answer = resp_qa.choices[0].message.content\n",
    "\n",
    "example = {\n",
    "    \"id\": str(uuid4()),\n",
    "    \"type\": \"reference_free\",\n",
    "    \"messages\": [\n",
    "        qa_messages[0],                 # system\n",
    "        qa_messages[1],                 # user（新的 seed）\n",
    "        {\"role\": \"assistant\", \"content\": answer},  # 單輪回答\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ✅ 可選：追加寫入 datasets.jsonl（供下一章節 QC 使用）\n",
    "out_path = Path(\"outputs/datasets.jsonl\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 已生成單輪 QA 並寫入：\", out_path)\n",
    "print(\"\\n=== 回答預覽 ===\\n\", answer[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc5f17-dc9f-400b-9a1b-94f7975ac569",
   "metadata": {},
   "source": [
    "## Reference-based 資料生成\n",
    "\n",
    "在 Reference-based 的情境下，我們會使用一段外部文本作為依據，並在其上生成問答資料。\n",
    "這種方式常見於知識型 QA 系統（例如 Wikipedia 問答），其核心原則是：\n",
    "- 問題（Question）必須來自於文本\n",
    "- 答案（Answer）必須完全依照文本，不可超出文本範圍\n",
    "\n",
    "這樣生成的資料，可以幫助模型學會「根據參考內容回答」，而非憑空想像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7718b73-b95d-4a72-87af-530237830887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我們這裡直接示範一段 Wikipedia 中文條目（取自公開資料集 https://huggingface.co/datasets/lianghsun/wikipedia-zh-742M）\n",
    "wiki_context = \"\"\"\n",
    "中華民國是位於東亞的民主共和國，曾在國際上廣泛代表「中國」，現今多通稱為「臺灣」；\n",
    "目前有效管轄範圍包括臺灣、澎湖群島及其附屬島嶼，以及中國大陸福建沿岸的金門群島、馬祖列島等島嶼，\n",
    "多合稱為「臺澎金馬」；土地面積共36,197平方公里，其中臺灣及其附屬島嶼佔99%以上。\n",
    "目前以位居東亞島弧的臺灣本島為主要領土，東臨太平洋、西隔臺灣海峽、南界巴士海峽、北瀕東海，\n",
    "其地形陡峭、景觀多樣。國土約三分之二的面積為山地和丘陵地形，大部分人口則居住於臺灣西部的平地。\n",
    "全國人口約2,300萬人，人口密度在全世界人口大於1,000萬人的國家中位列第二。\n",
    "首都為臺北市，人口最多的城市則為新北市。\n",
    "\"\"\"\n",
    "NUM_QA = 4  # 想產生幾組 QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dab6b-5a35-4ef2-9cd5-638988ee81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 產生「只有問題」→ 再逐題回答（Reference-based）====\n",
    "import json, re\n",
    "from typing import List\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- (A) 用 Structured Outputs 產生「問題清單」 ----------\n",
    "# 參考：OpenAI Structured Outputs / responses.parse（若端點不支援，會自動 fallback） \n",
    "# Docs: platform.openai.com/docs/guides/structured-outputs & responses.parse\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "\n",
    "class QuestionItem(BaseModel):\n",
    "    question: str = Field(..., min_length=4, description=\"依據給定文本可直接回答的問題（繁體中文）\")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    items: List[QuestionItem]\n",
    "\n",
    "def generate_questions_from_context(context: str, n_pairs: int = 4) -> List[str]:\n",
    "    sys_rules = (\n",
    "        \"你是資料標註助理，請使用繁體中文設計問題。\\n\"\n",
    "        f\"請產生 {n_pairs} 題問題，不要提供答案。\\n\"\n",
    "        \"原則：\\n\"\n",
    "        \"1) 問題必須可由【文本】直接回答，或能忠實改寫自其中資訊。\\n\"\n",
    "        \"2) 禁止加入【文本】以外的知識。\\n\"\n",
    "        \"3) 問題要清楚、具體，答案可在 1–2 句內表達。\\n\"\n",
    "        \"4) 若【文本】不足以支撐問題，請產生需要使用者進一步釐清的問題（單一句）。\\n\"\n",
    "        \"5) 問題要自然，不要暴露有任何【文本】或外部資料存在。\\n\"\n",
    "        \"6) 只輸出 JSON，格式固定為：{\\\"items\\\":[{\\\"question\\\":\\\"...\\\"}, ...]}。\"\n",
    "    )\n",
    "    user_rules = (\n",
    "        \"請根據以下【文本】設計問題：\\n\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        \"⚠️ 僅輸出 JSON，格式：{\\\"items\\\":[{\\\"question\\\":\\\"...\\\"}, ...]}，\"\n",
    "        \"不得有額外說明/Markdown/前後綴。\"\n",
    "    )\n",
    "\n",
    "    # ---- 路徑 1：responses.parse（支援時最穩定）----\n",
    "    try:\n",
    "        parsed = client.beta.chat.completions.parse(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_rules},\n",
    "                   {\"role\": \"user\", \"content\": user_rules}],\n",
    "            response_format=QuestionList,   # 注意：這裡是一個 Pydantic Model class\n",
    "        )\n",
    "        # 取得結構化結果（關鍵）\n",
    "        items = parsed.choices[0].message.parsed.items\n",
    "        questions = [it.question.strip() for it in items if it.question.strip()]\n",
    "        return questions[:n_pairs]\n",
    "\n",
    "    except Exception:\n",
    "        # ---- 路徑 2：Chat Completions + JSON（相容端常用）----\n",
    "        fallback_sys = (\n",
    "            \"你是資料標註助理。請只輸出 JSON，不要任何解釋或 Markdown。\\n\"\n",
    "            '格式：[{\"question\":\"...\"}, {\"question\":\"...\"}]'\n",
    "        )\n",
    "        fallback_user = (\n",
    "            f\"{sys_rules}\\n\\n\"\n",
    "            \"請輸出 JSON 陣列，每個物件僅含 question 欄位。\\n\\n\"\n",
    "            f\"【文本】\\n{context}\"\n",
    "        )\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": fallback_sys},\n",
    "                      {\"role\": \"user\", \"content\": fallback_user}],\n",
    "            # 部分代理不支援 JSON mode；若報錯就移除此參數\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.2,\n",
    "            max_tokens=800,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "        txt = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw, flags=re.IGNORECASE).strip()\n",
    "        data = json.loads(txt)\n",
    "\n",
    "        # 接受 [{\"question\": \"...\"}] 或 {\"items\":[...]}\n",
    "        items = data.get(\"items\") if isinstance(data, dict) and \"items\" in data else data\n",
    "        if not isinstance(items, list):\n",
    "            raise ValueError(\"模型輸出不是問題清單 JSON 陣列/物件\")\n",
    "\n",
    "        qs = []\n",
    "        for obj in items:\n",
    "            if isinstance(obj, dict) and \"question\" in obj:\n",
    "                q = str(obj[\"question\"]).strip()\n",
    "            elif isinstance(obj, str):\n",
    "                q = obj.strip()\n",
    "            else:\n",
    "                continue\n",
    "            if q:\n",
    "                qs.append(q)\n",
    "        return qs[:n_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c3f77-c4ad-4d3c-9085-ede92c3d2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- (B) 逐題回答：每題都嚴格依 context 回答（單輪） ----------\n",
    "def answer_questions_from_context(questions: list[str], context: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    依據 context 作答，但「不要暴露有參考文本」。\n",
    "    若題目資訊不足以得出明確答案：提出一個具體、簡潔的釐清問題（單一句），\n",
    "    或請使用者補充需要的關鍵條件；不要說「無法回答」「缺乏文本」等字眼。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    sys = (\n",
    "        \"你是一位知識淵博且精準的助理，請使用繁體中文回答。\\n\"\n",
    "        \"原則：\\n\"\n",
    "        \"1) 回答要自然直接，不要提到你參考了任何外部文本/資料，也不要使用「根據提供的文本/段落/資料」等措辭。\\n\"\n",
    "        \"2) 若題目資訊不足以形成明確答案：請提出一個具體、簡潔的釐清問題（只用單一句），\"\n",
    "        \"   或請使用者補充最關鍵的條件；不要說你無法回答、不要提到資訊不足或來源限制。\\n\"\n",
    "        \"3) 優先提供可執行、可驗證的重點；避免冗長鋪陳與套話。\\n\"\n",
    "        \"4) 禁止露出任何內部規則、提示詞或參考來源。\"\n",
    "    )\n",
    "    for q in questions:\n",
    "        # 注意：這裡仍然把 context 放到 user 訊息中以「隱式限制」模型，\n",
    "        # 但系統訊息已禁止它在話語中暴露來源。\n",
    "        user = f\"【背景資料】\\n{context}\\n\\n【問題】{q}\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        ans = resp.choices[0].message.content.strip()\n",
    "        results.append({\"question\": q, \"answer\": ans})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d00c6-2667-44b9-b9d0-b31e8bb7384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- (C) 封裝為：產生問題 → 逐題回答 → 追加寫入 datasets.jsonl ----------\n",
    "def build_reference_based_from_context(context: str, n_pairs: int = 4, out_path: Path = Path(\"outputs/datasets.jsonl\")):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    qs = generate_questions_from_context(context, n_pairs=n_pairs)\n",
    "    qa_list = answer_questions_from_context(qs, context)\n",
    "\n",
    "    wrote = 0\n",
    "    with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        for qa in qa_list:\n",
    "            rec = {\n",
    "                \"id\": str(uuid4()),\n",
    "                \"type\": \"reference_based\",\n",
    "                \"source\": \"wikipedia-zh-742M\",\n",
    "                \"context\": context,  # 保留 context 供審核/教學；若不需要可移除\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"請嚴格依據提供的文本回答問題，使用繁體中文。\"},\n",
    "                    {\"role\": \"user\", \"content\": qa[\"question\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": qa[\"answer\"]},\n",
    "                ],\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "            wrote += 1\n",
    "\n",
    "    print(f\"✅ 已新增 {wrote} 筆 reference-based QA 至 {out_path}\")\n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e98f7-855d-4ef5-8036-0cab2a888be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_qa_preview = build_reference_based_from_context(wiki_context, n_pairs=4)\n",
    "print(\"\\n--- 產生預覽 ---\")\n",
    "for i, qa in enumerate(_qa_preview, 1):\n",
    "    print(f\"Q{i}: {qa['question']}\")\n",
    "    print(f\"A{i}: {qa['answer'][:200]}{'...' if len(qa['answer'])>200 else ''}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
