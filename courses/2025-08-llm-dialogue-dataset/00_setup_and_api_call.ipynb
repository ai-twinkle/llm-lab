{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e018c4a-59f2-41b8-9872-c9d2bd087bcc",
   "metadata": {},
   "source": [
    "# 00 - 環境設定與首次呼叫 LLM API 🚀\n",
    "\n",
    "<div align=\"left\" style=\"line-height: 1;\">\n",
    "  <a href=\"https://discord.gg/Cx737yw4ed\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Twinkle%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "  <a href=\"https://huggingface.co/twinkle-ai\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Twinkle%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "在這個 Notebook 中，你將學會：\n",
    "- 如何設定環境與 API Key  \n",
    "- 如何呼叫 Twinkle AI 社群提供的 **Gemma-3-12B-it** 免費 API  \n",
    "- 如何撰寫最小化的 API client  \n",
    "- 實際體驗一次最簡單的 Prompt → Response 流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40149fa-a150-4daf-87d1-0221166199e4",
   "metadata": {},
   "source": [
    "## 1. 安裝必要套件\n",
    "\n",
    "我們將使用 [OpenAI Python SDK](https://pypi.org/project/openai/)  \n",
    "這個 SDK 與多數 **OpenAI 相容 API** 完全相容，適合拿來呼叫 Twinkle AI 提供的端點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f206346-c020-415f-a876-7baf1ef8b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ 安裝最新版本 OpenAI SDK\n",
    "!pip -q install --upgrade openai>=1.40.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8750e-f913-4ec4-8938-b4b829024270",
   "metadata": {},
   "source": [
    "## 2. 設定 API Key 與 Base URL\n",
    "\n",
    "- **API Key**：這是存取 LLM API 服務的金鑰，請向 **Twinkle AI 社群** 索取。  \n",
    "- **Base URL**：我們使用的服務端點是  \n",
    "  `https://litellm-ekkks8gsocw.dgx-coolify.apmic.ai/v1`\n",
    "\n",
    "這裡我們直接在程式碼中輸入字串，方便初學者快速上手。  \n",
    "（⚠️ 在真實專案中，建議還是使用**環境變數**或**密鑰管理工具**。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeaff20-ded3-482c-ae6d-56972d29fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# ⚠️ 這裡請向 Twinkle AI 社群詢問 API Key\n",
    "API_KEY = \"\"  # 註解：這裡要問 Twinkle AI 社群\n",
    "BASE_URL = \"https://litellm-ekkks8gsocw.dgx-coolify.apmic.ai\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=f\"{BASE_URL}/v1\"  # 多數相容端點的 API prefix 是 /v1\n",
    ")\n",
    "\n",
    "MODEL = \"gemma-3-12b-it\"  # Twinkle 端提供的可用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d78e545-772a-4f0f-b07e-8364b7d3a583",
   "metadata": {},
   "source": [
    "## 3. 發送第一次 Chat Completion\n",
    "\n",
    "我們來嘗試一個最小化的對話呼叫：  \n",
    "- `system`：這是對模型的「角色指令」（system prompt），用來告訴模型要以什麼身份、什麼語氣來回應。例如，你可以指定它是「專業助理」、「法律顧問」或「客服人員」。這個設定會影響模型回應的風格與用詞。\n",
    "- `user`：代表使用者的輸入內容，也就是我們真正想問的問題或任務描述。模型會依照前面 system 的角色設定來解讀並生成回答。 \n",
    "- `temperature`：控制生成的多樣性（0.7 代表中等創意）  \n",
    "- `max_tokens`：限制模型回傳的字數\n",
    "\n",
    "如果呼叫成功，會收到一個包含回應的 JSON 結構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab919d9b-39d8-4da5-bf78-1de1c5fcbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是專業的助理，使用繁體中文回答。\"},\n",
    "            {\"role\": \"user\", \"content\": \"請用一句話介紹什麼是大型語言模型（LLM）。\"}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "    )\n",
    "    print(\"✅ 呼叫成功\")\n",
    "except Exception as e:\n",
    "    print(\"❌ 呼叫失敗，請檢查 API Key / base_url / 模型名稱是否正確。\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713d2b6-43d9-4359-ac60-1e610b1b48b0",
   "metadata": {},
   "source": [
    "## 4. 解析並顯示模型回應\n",
    "\n",
    "成功呼叫後，回傳物件中會包含多個 `choices`，每個 choice 都有一段 `message.content`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e319a2-17fc-4d53-9125-4b94fc98c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resp.choices:\n",
    "    print(\"=== Model Output ===\")\n",
    "    print(resp.choices[0].message.content)\n",
    "else:\n",
    "    import json\n",
    "    print(\"⚠️ 非預期回傳格式：\")\n",
    "    print(json.dumps(resp.model_dump(), ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
